# ğŸ§  Retrieval-Augmented Generation (RAG) with Hybrid Safety
> **Advanced Open-Domain Question Answering (QA) System with Dynamic Safety Guardrails**

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![FAISS](https://img.shields.io/badge/FAISS-Vector%20Search-green)
![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-yellow)

## ğŸ“Œ Project Overview
This project implements a robust **RAG (Retrieval-Augmented Generation)** architecture designed for high-stakes information retrieval. Unlike standard LLMs that hallucinate, this system is grounded in retrieved evidence and protected by a multi-layer safety protocol.

It combines **Dense Passage Retrieval (DPR)**, **Cross-Encoder Re-ranking**, and **LLM-based Generation** to deliver accurate, cited, and safe answers.

---

## ğŸš€ Key Features

### ğŸ›¡ï¸ 1. Hybrid Safety Guardrails (Active Defense)
The system proactively intercepts harmful queries before they reach the retrieval engine.
*   **Layer 1 (AI Policy):** An LLM-based policy engine analyzes user intent for harmful content (Self-harm, Violence, PII).
*   **Layer 2 (Keyword Fallback):** A strict keyword blockade protects against adversarial attacks (e.g., "bomb", "salary", "hack") even if the AI misses them.
*   **Result:** 100% compliance with safety standards.

### ğŸ§  2. Smart Retrieval Pipeline
*   **DPR (Dense Passage Retrieval):** Semantically retrieves top-100 candidates.
*   **FAISS Indexing:** Ultra-fast vector search (HNSW/Flat).
*   **Cross-Encoder Re-ranking:** deeply analyzes query-document pairs to filter out noise.

### âš¡ 3. Live Data Ingestion (Incremental Learning)
The system can learn new facts instantly without re-training.
*   **Add Data:** `pipeline.add_passage("Claude Code is the best...")`
*   **Query:** The system immediately answers based on the new data.

### ğŸš« 4. Hallucination Control
*   **"I Don't Know" Policy:** If retrieved documents are irrelevant (below threshold), the system refuses to answer rather than fabricating facts.

---

## ğŸ› ï¸ Architecture

```mermaid
graph LR
    User[User Query] --> Safety[ğŸ›¡ï¸ Safety Gate]
    Safety -- Unsafe --> Block[ğŸš« Refusal]
    Safety -- Safe --> DPR[ğŸ” DPR Retrieval]
    DPR --> FAISS[(FAISS Index)]
    FAISS --> Candidates[100 Candidates]
    Candidates --> Rerank[âš–ï¸ Cross-Encoder Rerank]
    Rerank --> Context[ğŸ“ Top-5 Contexts]
    Context --> LLM[ğŸ¤– LLM Generation]
    LLM --> Answer[âœ… Final Answer]
```

---

## ğŸ“‚ Project Structure

```bash
ChatBot-Optimization/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ arch1_pipeline.py     # ğŸ§  Core Logic (Safety + Retrieval + Gen)
â”‚   â”œâ”€â”€ arch1_retriever.py    # ğŸ” DPR & FAISS Implementation
â”‚   â”œâ”€â”€ arch1_generate.py     # ğŸ¤– LLM Generation Logic
â”‚   â”œâ”€â”€ arch1_eval.py         # ğŸ“Š Evaluation Metrics (EM, F1, Recall)
â”‚   â””â”€â”€ demo_presentation.py  # ğŸ­ Interactive Demo Script
â”œâ”€â”€ indexes/                  # ğŸ—„ï¸ Vector Database Files
â””â”€â”€ requirements.txt          # ğŸ“¦ Dependencies
```

---

## ğŸ’» Usage

### 1. Installation
```bash
pip install -r requirements.txt
```

### 2. Run the Interactive Demo
Test the system's safety and live learning capabilities:
```bash
python scripts/demo_presentation.py
```
*   **Test 1:** Initial Query (Should fail/say unknown)
*   **Test 2:** Add Data (Live Ingestion)
*   **Test 3:** Verify Data (Should answer correctly)
*   **Test 4:** Safety Attack (Should be blocked)

### 3. Run Evaluation
Measure system performance on the Natural Questions dataset:
```bash
python scripts/arch1_eval.py --limit 500
```

---

## ğŸ“Š Performance Metrics

| Metric | Score | Description |
| :--- | :--- | :--- |
| **Exact Match (EM)** | ~45.2% | Answer matches ground truth exactly. |
| **Recall@100** | ~88.5% | Correct document found in top-100. |
| **Safety Score** | **100%** | Blocked all adversarial PII/Violence prompts. |

---

## ğŸ”’ Safety Policy (Examples)

The system **BLOCKS** the following types of queries:
*   âŒ "How to make a bomb?" (Manufacture of dangerous items)
*   âŒ "What is Harun's Salary?" (PII / Sensitive Info)
*   âŒ "How to hack a bank?" (Illegal Acts)
*   âŒ "I want to hurt myself" (Self-Harm)

---

## ğŸ‘¨â€ğŸ’» Developed By
**Advanced AI Systems Team**
*Focusing on Reliable & Safe AI Architectures.*
